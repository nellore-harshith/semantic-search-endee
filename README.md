# ğŸ” Semantic Search using Endee

## ğŸ“Œ Project Overview
This project implements a **Semantic Search System** that retrieves documents based on **meaning and context**, rather than exact keyword matching.  
It uses **sentence embeddings** generated by a transformer model and applies **cosine similarity** to rank documents by relevance.

The project demonstrates how semantic search works internally and how vector representations of text can be stored and searched efficiently.

---

## ğŸ¯ Use Case Demonstrated
Traditional keyword search fails when queries and documents use different words with similar meaning.  
Semantic search solves this problem by understanding context.

Example:
- Query: *"AI used in search engines"*
- Result: Documents about **Artificial Intelligence**, **Machine Learning**, and **Python for AI**, even if the exact words do not match.

---

## ğŸ§  Technologies Used
- Python  
- Sentence Transformers (`all-MiniLM-L6-v2`)  
- NumPy  
- Endee (vector database interface)  
- Cosine Similarity  

---

## ğŸ§© How Endee Is Used
Endee was evaluated and used as the **vector database interface**.  
Due to SDK constraints in local environments, embeddings are stored locally using a structure that follows an **Endee-compatible vector design**.

This ensures that:
- The architecture remains aligned with Endeeâ€™s vector search principles  
- The workflow matches real-world vector database usage  
- The project can run fully offline  

---

## âš™ï¸ Setup & Run Instructions
Create virtual environment, activate it, and install dependencies:
```bash

python -m venv venv

```
## âš™ï¸ Activate Environment
```bash

venv\Scripts\activate

```
## âš™ï¸ Instal Dependencies
```bash

pip install sentence-transformers numpy endee

```
## FINALLY

## RUN THE PROJECT

# Step 1: Ingest documents and generate embeddings
```bash

python ingest.py

```
# Step 2: Perform semantic search
```bash 
python search.py

```


